{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299077be-75d7-458e-a2f0-8d99b30a0415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('kick.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc7f5f-2991-4c8b-bf89-3f87027b49df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa1551c-7602-4311-8c76-9b8159e9f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be71e4-c645-485e-8d6d-1b858b889a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auction: imputation(nan -> OTHER)\n",
    "df['Auction'] = df['Auction'].fillna('OTHER')\n",
    "\n",
    "# VehYear: imputation(nan -> median)\n",
    "df['VehYear'] = df['VehYear'].fillna(df['VehYear'].median())\n",
    "\n",
    "# Transmission: imputation (?, nan -> UNKNOWN)\n",
    "df['Transmission'] = df['Transmission'].str.upper()\n",
    "df['Transmission'] = df['Transmission'].replace('?',np.nan)\n",
    "df['Transmission'] = df['Transmission'].fillna('UNKNOWN')\n",
    "\n",
    "# Make: imputation(nan -> UNKNOWN)\n",
    "df['Make'] = df['Make'].fillna('UNKNOWN')\n",
    "\n",
    "# VehOdo: imputation(replace outliers with the median value)\n",
    "lower_bound = 1000\n",
    "upper_bound = 400000\n",
    "\n",
    "vehodo_median = df['VehOdo'].median()\n",
    "\n",
    "df.loc[(df['VehOdo'] < lower_bound)|(df['VehOdo'] > upper_bound), 'VehOdo'] = np.nan\n",
    "\n",
    "df['VehOdo'] = df['VehOdo'].fillna(vehodo_median)\n",
    "\n",
    "# Nationality: imputation(USA -> AMERICAN, ? -> nan, nan ->UNKNOWN)\n",
    "df['Nationality'] = df['Nationality'].str.upper().str.strip()\n",
    "df['Nationality'] = df['Nationality'].replace('USA', 'AMERICAN')\n",
    "df['Nationality'] = df['Nationality'].replace('?', np.nan)\n",
    "df['Nationality'] = df['Nationality'].fillna('UNKNOWN')\n",
    "\n",
    "# TopThreeAmericanName: imputation(? -> nan, nan -> UNKNOWN)\n",
    "df['TopThreeAmericanName'] = df['TopThreeAmericanName'].replace('?', np.nan)\n",
    "df['TopThreeAmericanName'] = df['TopThreeAmericanName'].fillna('UNKNOWN')\n",
    "\n",
    "# ForSale: upper, imputation(?,0 -> nan / nan-> UNKNOWN)\n",
    "df['ForSale'] = df['ForSale'].str.upper().str.strip()\n",
    "df['ForSale'] = df['ForSale'].replace('?', np.nan)\n",
    "df['ForSale'] = df['ForSale'].replace('0', np.nan)\n",
    "for_sale_map = {'YES': 0, 'NO': 1}\n",
    "df['ForSale'] = df['ForSale'].map(for_sale_map)\n",
    "df['ForSale'] = df['ForSale'].fillna('UNKNOWN')\n",
    "\n",
    "# MMR Prices\n",
    "# imputation: ?,0-> nan / change to number /nan -> median value\n",
    "mmr_current_cols = ['MMRCurrentAuctionAveragePrice','MMRCurrentAuctionCleanPrice', \n",
    "                    'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice']\n",
    "\n",
    "for col in mmr_current_cols:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "    df[col] = df[col].replace('?', np.nan)\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df[col] = df[col].replace(0, np.nan)\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "mmr_acquisition_cols = ['MMRAcquisitionAuctionAveragePrice','MMRAcquisitionAuctionCleanPrice', \n",
    "                    'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice']\n",
    "\n",
    "for col in mmr_acquisition_cols:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "    df[col] = df[col].replace('?', np.nan)\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df[col] = df[col].replace(0, np.nan)\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# outlier: quantile 1% and 99%  -> nan -> median value\n",
    "for col in mmr_current_cols + mmr_acquisition_cols:\n",
    "    lower_limit = df[col].quantile(0.01)\n",
    "    upper_limit = df[col].quantile(0.99)\n",
    "    df.loc[(df[col] < lower_limit) | (df[col] > upper_limit), col] = np.nan\n",
    "    df[col] = df[col].fillna(df[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40cbe39-69b5-413d-a1fd-26fb0355e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['ForSale'].describe())\n",
    "print(df['ForSale'].unique())\n",
    "print(df['ForSale'].value_counts())\n",
    "print(df['VehOdo'].value_counts(bins=10)) #only numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f75c2c8-b8b6-463f-9c34-e5bd1fb50ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['Auction', 'VehYear', 'Make', 'Transmission', 'VehOdo',\n",
    "                 'Nationality', 'TopThreeAmericanName',\n",
    "                 'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice',\n",
    "                 'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice',\n",
    "                 'MMRCurrentRetailRatio', 'ForSale', 'IsBadBuy']\n",
    "df_selected = df[selected_cols].copy()\n",
    "print(df_selected.describe())\n",
    "print(\"================================================================\")\n",
    "for col in df_selected.columns:\n",
    "    print(df_selected[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc116f-78be-4f9c-b242-299f6474e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=df, x='IsBadBuy')\n",
    "plt.title('Distribution of IsBadBuy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ddf67-20df-4b38-9694-85c959cb5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df['VehOdo'], kde=True, bins=50)\n",
    "plt.title('Distribution of Vehicle Odometer (VehOdo)')\n",
    "plt.xlabel('VehOdo')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4891293-b359-4734-b8ee-63a0318761b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"IsBadBuy\", y=\"VehOdo\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585dc55e-78f2-427a-a787-a2d1e95740d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df[mmr_current_cols + mmr_acquisition_cols].corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e8725-294f-428c-b4ed-c5575bfc8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "correlation_mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", \n",
    "            annot_kws={'size': 8}, cmap='coolwarm', \n",
    "            center=0, mask=correlation_mask, square=True)\n",
    "plt.title('Correlation Matrix of MMR Variables')\n",
    "plt.show()\n",
    "# we use one value of MMR variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7d1859-8a01-462c-a70a-ce54ed47b199",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the result between before and after preprocessing\n",
    "df_selected_original = df_original[selected_cols].copy()\n",
    "df_selected_processed = df[selected_cols].copy()\n",
    "\n",
    "for col in selected_cols:\n",
    "    print(f\"===== Column: {col}========\")\n",
    "    if df[col].dtype in ['int64', 'float64']:\n",
    "        print(\"Before preprocessing:\")\n",
    "        print(df_selected_original[col].describe())\n",
    "        print(\"====================================\")\n",
    "        print(\"After preprocessing:\")\n",
    "        print(df_selected_processed[col].describe())\n",
    "    else:\n",
    "        print(\"Before preprocessing:\")\n",
    "        print(df_selected_original[col].value_counts(dropna=False))\n",
    "        print(\"====================================\")\n",
    "        print(\"After preprocessing:\")\n",
    "        print(df_selected_processed[col].value_counts(dropna=False))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1a2538-0390-41ea-9993-089012ffbcd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['Auction', 'Make', 'Transmission', 'Nationality', \n",
    "                    'TopThreeAmericanName', 'ForSale']\n",
    "for col in categorical_cols:\n",
    "    print(f\"=== {col} ===\")\n",
    "    print(\"*** Before preprocessing ***\")\n",
    "    print(df_original.groupby('IsBadBuy')[col].value_counts(normalize=True))\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"*** After preprocessing ***\")\n",
    "    print(df.groupby('IsBadBuy')[col].value_counts(normalize=True))\n",
    "    print(\"======================================\\n\")\n",
    "\n",
    "# the proportion of values of the target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9edf5e-93ca-4fda-a960-a26ccb7d2d68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_cols = ['VehYear', 'VehOdo', 'MMRCurrentAuctionAveragePrice','MMRCurrentAuctionCleanPrice', \n",
    "                'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice']\n",
    "for col in numeric_cols:\n",
    "    print(f\"=== {col} ===\")\n",
    "    print(\"*** Before preprocessing ***\")\n",
    "    print(df_original.groupby('IsBadBuy')[col].describe())\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"*** After preprocessing ***\")\n",
    "    print(df.groupby('IsBadBuy')[col].describe())\n",
    "    print(\"======================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c15f2-3bf5-4d91-92ca-1e06598a7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    'PurchaseID', 'PurchaseTimestamp', 'PurchaseDate', 'Make',\n",
    "    'Color', 'WheelTypeID', 'WheelType', 'Size', 'TopThreeAmericanName', 'MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionAuctionCleanPrice', \n",
    "    'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice', 'MMRCurrentAuctionCleanPrice', 'MMRCurrentRetailCleanPrice', \n",
    "    'MMRCurrentRetailRatio', 'WarrantyCost', 'ForSale',\n",
    "    'PRIMEUNIT', 'AUCGUART', 'VNST', 'VehBCost', 'IsOnlineSale'\n",
    "]\n",
    "df.drop(columns=drop_cols, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edeb2d5-26a7-4bd8-9c0f-2c978f53983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36d3f5-d0bb-4b11-9fe7-6236eaaa6667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942021ee-7f74-4e88-85f1-cf16d6330253",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['IsBadBuy'].values\n",
    "X = df.drop('IsBadBuy', axis=1)\n",
    "feature_names =X.columns\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290017d3-b379-4255-9a84-b19fd9ae0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 10\n",
    "test_set_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, stratify=y, random_state=random_state)\n",
    "\n",
    "print(\"Size of training set:\", len(X_train))\n",
    "print(\"Size of testing set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c87042-77f8-4418-b9fa-780400852b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#simple decision tree training\n",
    "model = DecisionTreeClassifier(random_state=random_state)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c11b1-32c2-4a04-84ee-e97cd23c74b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****Model parameters*****\\n', model.get_params(deep=True))\n",
    "print('Number of leaves in the trained model:', model.get_n_leaves())\n",
    "print(\"Number of nodes:\", model.tree_.node_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894840fb-3bd0-43a0-b62c-0181b27195ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set accuracy:\", model.score(X_train, y_train)) #overfitting\n",
    "print(\"Testing set accuracy:\", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b549fb1a-7191-416a-9a49-12d1a6265f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0da6ce1-3c04-4319-a312-3f010000ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6915668-514b-4903-974b-8fc58985f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_feature_importances(model, feature_names, features_to_display=20):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)\n",
    "    indices = np.flip(indices, axis=0)\n",
    "\n",
    "    indices = indices[:features_to_display]\n",
    "    for i in indices:\n",
    "        print(feature_names[i], ':', importances[i])\n",
    "    print(\"Number of leaves:\", model.get_n_leaves())\n",
    "    \n",
    "display_feature_importances(model, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b000d-f05c-4a32-9e92-a7bad4cd06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from io import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "def visualize_model(model):\n",
    "    dotfile = StringIO()\n",
    "    export_graphviz(model, out_file=dotfile, feature_names=feature_names)\n",
    "\n",
    "    graph = pydot.graph_from_dot_data(dotfile.getvalue())\n",
    "    display(Image(graph[0].create_png()))\n",
    "\n",
    "visualize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d143b73-a34b-4eb2-a005-cbe7edec1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small = DecisionTreeClassifier(\n",
    "    max_depth=3,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=random_state\n",
    ") \n",
    "\n",
    "model_small.fit(X_train, y_train)\n",
    "\n",
    "y_pred =model_small.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Node, leaves, depth\n",
    "print(\"Nodes:\", model_small.tree_.node_count)\n",
    "print(\"Leaves:\", model_small.get_n_leaves())\n",
    "print(\"Depth:\", model_small.get_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87da0ed-663c-4a8f-9289-4325425465ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small = DecisionTreeClassifier(\n",
    "    max_depth=3, \n",
    "    class_weight='balanced',\n",
    "    random_state=random_state\n",
    ") \n",
    "#'class_weight'can balance the class\n",
    "\n",
    "model_small.fit(X_train, y_train)\n",
    "\n",
    "y_pred =model_small.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Node, leaves, depth\n",
    "print(\"Nodes:\", model_small.tree_.node_count)\n",
    "print(\"Leaves:\", model_small.get_n_leaves())\n",
    "print(\"Depth:\", model_small.get_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ec34d-4813-41d6-bf2c-c7119f7ee84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_feature_importances(model_small, feature_names)\n",
    "visualize_model(model_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f902d69-671c-46f0-bc5d-ad1568dbcd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = []\n",
    "train_score = []\n",
    "for max_depth in range(2,21):\n",
    "    temp_model = DecisionTreeClassifier(max_depth=max_depth, class_weight=\"balanced\", random_state=random_state)\n",
    "    temp_model.fit(X_train, y_train)\n",
    "    test_score.append(temp_model.score(X_test, y_test))\n",
    "    train_score.append(temp_model.score(X_train, y_train))\n",
    "\n",
    "plt.plot(range(2,21), train_score, 'b', range(2,21), test_score, 'r')\n",
    "plt.xlabel('max_depth\\nBlue = training acc. Red = test acc.')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad5d97-75b2-4bf3-bc74-6d97a5d84b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = []\n",
    "train_score = []\n",
    "for max_depth in range(10,15):\n",
    "    temp_model = DecisionTreeClassifier(max_depth=max_depth, class_weight=\"balanced\", random_state=random_state)\n",
    "    temp_model.fit(X_train, y_train)\n",
    "    test_score.append(temp_model.score(X_test, y_test))\n",
    "    train_score.append(temp_model.score(X_train, y_train))\n",
    "\n",
    "plt.plot(range(10,15), train_score, 'b', range(10,15), test_score, 'r')\n",
    "plt.xlabel('max_depth\\nBlue = training acc. Red = test acc.')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243b551-ff0f-4c38-9fe1-21a7edc9b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = []\n",
    "train_score = []\n",
    "for max_depth in range(5,10):\n",
    "    temp_model = DecisionTreeClassifier(max_depth=max_depth, class_weight=\"balanced\", random_state=random_state)\n",
    "    temp_model.fit(X_train, y_train)\n",
    "    test_score.append(temp_model.score(X_test, y_test))\n",
    "    train_score.append(temp_model.score(X_train, y_train))\n",
    "\n",
    "plt.plot(range(5,10), train_score, 'b', range(5,10), test_score, 'r')\n",
    "plt.xlabel('max_depth\\nBlue = training acc. Red = test acc.')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1badf055-0125-4e81-975b-0cb76e6d4486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score = []\n",
    "train_score = []\n",
    "for max_depth in range(2, 5):\n",
    "    temp_model = DecisionTreeClassifier(max_depth=max_depth, class_weight=\"balanced\", random_state=random_state)\n",
    "    temp_model.fit(X_train, y_train)\n",
    "    test_score.append(temp_model.score(X_test, y_test))\n",
    "    train_score.append(temp_model.score(X_train, y_train))\n",
    "\n",
    "plt.plot(range(2, 5), train_score, 'b', range(2, 5), test_score, 'r')\n",
    "plt.xlabel('max_depth\\nBlue = training acc. Red = test acc.')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b5657-704a-40ee-8ee0-b5b606ad53a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(10, 15),\n",
    "    'min_samples_leaf': range(20, 60, 10)\n",
    "}\n",
    "\n",
    "def perform_grid_search(X_train, y_train, X_test, y_test, params, num_folds=10):\n",
    "    cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=random_state, class_weight='balanced'), cv=num_folds, verbose=1, n_jobs=-1)\n",
    "    cv.fit(X_train,y_train)\n",
    "\n",
    "    print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "    print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "    y_pred = cv.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(cv.best_params_)\n",
    "    return cv\n",
    "    \n",
    "cv = perform_grid_search(X_train, y_train, X_test, y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4819b467-3e19-4713-aae6-5b78efac8731",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(2,5),\n",
    "    'min_samples_leaf': range(5, 20, 10)\n",
    "}\n",
    "cv= perform_grid_search(X_train, y_train, X_test, y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af829e5-75e1-472e-b109-483887b5e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(5,8),\n",
    "    'min_samples_leaf': range(5, 10)\n",
    "}\n",
    "cv = perform_grid_search(X_train, y_train, X_test, y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d8674-7f26-4778-8cc9-d71bf03a0e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(2, 4),\n",
    "    'min_samples_leaf': range(5, 50, 10)\n",
    "}\n",
    "cv= perform_grid_search(X_train, y_train, X_test, y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d31bd1-a0c7-482e-b5c7-222a54fd2bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv= cv.best_estimator_\n",
    "visualize_model(model_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c39fa2c-bc04-44b8-81ed-4252a7a5a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_feature_importances(model_cv, feature_names)\n",
    "visualize_model(model_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949cebac-68f2-405a-af72-7b2b907ec308",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nodes:\", model_cv.tree_.node_count)\n",
    "print(\"Leaves:\", model_cv.get_n_leaves())\n",
    "print(\"Depth:\", model_cv.get_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379e16f-9476-40f9-9f5b-f6ef9099fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_cv.predict(X_test)\n",
    "y_pred_proba_dt = model_cv.predict_proba(X_test)\n",
    "\n",
    "print(\"Probability produced by decision tree for each class vs actual prediction on Target (0 = clean, 1 = BadBuy).\")\n",
    "print(\"You should be able to see the default threshold of 0.5.\")\n",
    "print(\"(Probs on zero)  (probs on one)  (prediction made)  (label)\")\n",
    "\n",
    "for i in range(20):\n",
    "    print(f\"{y_pred_proba_dt[i][0]:.13f}  {y_pred_proba_dt[i][1]:.13f}  {y_pred[i]:<10d}  {y_test[i]:10d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f532371-bc90-4a05-bb71-89479d166920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred_proba_dt = model.predict_proba(X_test)\n",
    "y_pred_proba_dt_small = model_small.predict_proba(X_test)\n",
    "y_pred_proba_dt_cv = model_cv.predict_proba(X_test)\n",
    "\n",
    "roc_index_dt = roc_auc_score(y_test, y_pred_proba_dt[:, 1])\n",
    "roc_index_dt_small = roc_auc_score(y_test, y_pred_proba_dt_small[:, 1])\n",
    "roc_index_dt_cv = roc_auc_score(y_test, y_pred_proba_dt_cv[:, 1])\n",
    "\n",
    "print(\"ROC index on test for default model:\", roc_index_dt)\n",
    "print(\"ROC index on test for small model:\", roc_index_dt_small)\n",
    "print(\"ROC index on test for grid search model:\", roc_index_dt_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21056cb7-38c4-4564-b6a1-942aea06087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr_dt, tpr_dt, thresholds_dt = roc_curve(y_test, y_pred_proba_dt[:,1])\n",
    "fpr_dt_small, tpr_dt_small, thresholds_dt_small = roc_curve(y_test, y_pred_proba_dt_small[:,1])\n",
    "fpr_dt_cv, tpr_dt_cv, thresholds_dt_cv = roc_curve(y_test, y_pred_proba_dt_cv[:,1])\n",
    "\n",
    "plt.plot(fpr_dt, tpr_dt, label='ROC Curve for default tree {:.3f}'.format(roc_index_dt), color='red', lw=0.5)\n",
    "plt.plot(fpr_dt_small, tpr_dt_small, label='ROC Curve for small tree{:.3f}'.format(roc_index_dt_small), color='green', lw=0.5)\n",
    "plt.plot(fpr_dt_cv, tpr_dt_cv, label='ROC Curve for grid search{:.3f}'.format(roc_index_dt_cv), color='blue', lw=0.5)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=0.5, label='Baseline', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c604a182-6fa8-4851-b212-fe421d2e2fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('decision_tree_model.pickle', 'wb') as f:\n",
    "    pickle.dump([model_cv, roc_index_dt_cv, fpr_dt_cv, tpr_dt_cv], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1bf2a6-76ce-47de-b75c-c4e1215e9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 10\n",
    "test_set_size = 0.3 # 30%\n",
    "print(\"Size of training set:\", len(X_train))\n",
    "print(\"Size of testing set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9441d00c-b24c-42d1-a07a-88bf2e306abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "print(\"Before scaling\\n-------------\")\n",
    "for i in range(5):\n",
    "    col = X_train[:,i]\n",
    "    print(\"Variable #{}: min {}, max {}, mean {:.2f} and std dev {:.2f}\".format(i, min(col), max(col), np.mean(col), np.std(col)))\n",
    "\n",
    "X_train = scaler.fit_transform(X_train, y_train)\n",
    "\n",
    "print(\"After scaling\\n-------------\")\n",
    "for i in range(5):\n",
    "    col = X_train[:,i]\n",
    "    print(\"Variable #{}: min {}, max {}, mean {:.2f} and std dev {:.2f}\".format(i, min(col), max(col), np.mean(col), np.std(col)))\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235e58b-be6e-4269-ae25-644706e385bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=random_state)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94236616-84a2-4032-b28a-6aca3277754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Training accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734fb6e9-513f-40cf-840e-4ffed3f03849",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ea243-3e68-458f-99ec-3e1daae2b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = model.coef_[0]\n",
    "\n",
    "coef = coef[:20]\n",
    "for i in range(len(coef)):\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b7cc2-3c8b-4cc0-97e9-5c65d7743a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = model.coef_[0]\n",
    "\n",
    "indices = np.argsort(np.absolute(coef))\n",
    "indices = np.flip(indices, axis=0)\n",
    "\n",
    "indices = indices[:20]\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ba7e4-82f2-41ce-a0fe-78b86b6318a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params,\n",
    "                  estimator=LogisticRegression(random_state=random_state, class_weight='balanced'),\n",
    "                  cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08222499-01f6-43a6-bd43-1989e8159748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_skewed_columns(df):\n",
    "    f, axes = plt.subplots(2,2, figsize=(12,10), sharex=False)\n",
    "\n",
    "    sns.kdeplot(df['VehYear'].dropna(), ax=axes[0,0])\n",
    "    sns.kdeplot(df['VehOdo'].dropna(), ax=axes[0,1])\n",
    "    sns.kdeplot(df['MMRCurrentAuctionAveragePrice'].dropna(), ax=axes[1,0])\n",
    "    sns.kdeplot(df['MMRCurrentRetailAveragePrice'].dropna(), ax=axes[1,1])\n",
    "    plt.show()\n",
    "plot_skewed_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020cecae-8b34-4f4b-b2a1-899cd2f86aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_transform = [\n",
    "    'VehYear', 'VehOdo', 'MMRCurrentAuctionAveragePrice', 'MMRCurrentRetailAveragePrice'\n",
    "]\n",
    "\n",
    "df_log = df.copy()\n",
    "\n",
    "for col in columns_to_transform:\n",
    "    df_log[col] = df_log[col].apply(lambda x: x+1)\n",
    "    df_log[col] = df_log[col].apply(np.log)\n",
    "\n",
    "plot_skewed_columns(df_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015b5850-218c-48dd-ae4a-4626bf86943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = df_log['IsBadBuy']\n",
    "X_log = df_log.drop(['IsBadBuy'], axis=1)\n",
    "X_mat_log = X_log.values\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X_mat_log, y_log,test_size=0.3, stratify=y_log, random_state=random_state)\n",
    "\n",
    "scaler_log = StandardScaler()\n",
    "X_train_log = scaler_log.fit_transform(X_train_log, y_train_log)\n",
    "X_test_log = scaler_log.transform(X_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069bd065-05cb-4198-8a92-4eddc408792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=random_state, class_weight='balanced'), \n",
    "                  cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_log, y_train_log)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train_log, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(X_test_log, y_test_log))\n",
    "\n",
    "y_pred = cv.predict(X_test_log)\n",
    "print(classification_report(y_test_log, y_pred))\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3020806-fb65-45a9-a7ce-08dd9158cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "rfe = RFECV(estimator = LogisticRegression(random_state=random_state, class_weight='balanced'), cv=10)\n",
    "\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "print(\"Original feature set\", X_train.shape[1])\n",
    "print(\"Number of features after elimination\", rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e848d7c4-0676-4229-8005-1748c1a0952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = feature_names[rfe.support_]\n",
    "print(\"Selected features: \", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8535117c-627d-405b-a67c-554381984450",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sel = rfe.transform(X_train)\n",
    "X_test_sel = rfe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad9bcd-1d20-4af2-a19f-1756b2e64809",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "rfe_cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=random_state, class_weight='balanced'), \n",
    "                  cv=10, n_jobs=-1)\n",
    "rfe_cv.fit(X_train_sel, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", rfe_cv.score(X_train_sel, y_train))\n",
    "print(\"Test accuracy:\", rfe_cv.score(X_test_sel, y_test))\n",
    "\n",
    "y_pred = rfe_cv.predict(X_test_sel)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(rfe_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e0c86-2ac0-4b4b-a126-f131bcad7098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running RFE + log transformation\n",
    "rfe_log = RFECV(estimator = LogisticRegression(random_state=random_state, class_weight='balanced'), \n",
    "                cv=5)\n",
    "rfe_log.fit(X_train_log, y_train_log)\n",
    "\n",
    "print(\"Original feature set\", X_train_log.shape[1])\n",
    "print(\"Number of features after elimination\", rfe.n_features_)\n",
    "\n",
    "X_train_sel_log = rfe_log.transform(X_train_log)\n",
    "X_test_sel_log = rfe_log.transform(X_test_log)\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "rfe_log_cv = GridSearchCV(param_grid=params,\n",
    "                          estimator=LogisticRegression(random_state=random_state, class_weight='balanced'), \n",
    "                          cv=10, n_jobs=-1)\n",
    "rfe_log_cv.fit(X_train_sel_log, y_train_log)\n",
    "\n",
    "\n",
    "print(\"Train accuracy:\", rfe_log_cv.score(X_train_sel_log, y_train_log))\n",
    "print(\"Test accuracy:\", rfe_log_cv.score(X_test_sel_log, y_test_log))\n",
    "\n",
    "y_pred_log = rfe_log_cv.predict(X_test_sel_log)\n",
    "print(classification_report(y_test_log, y_pred_log))\n",
    "\n",
    "print(\"Best parameters:\", rfe_log_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91b43f-423a-4d43-a57d-448c7b99e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('decision_tree_model.pickle','rb') as f:\n",
    "    dt_best, roc_index_dt_cv, fpr_dt_cv, tpr_dt_cv = pickle.load(f)\n",
    "\n",
    "def display_feature_importances(model, feature_names, features_to_display=20):\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    indices = np.argsort(importances)\n",
    "    indices = np.flip(indices, axis=0)\n",
    "\n",
    "    indices = indices[:features_to_display]\n",
    "    for i in indices:\n",
    "        print(feature_names[i], ':', importances[i])\n",
    "    print(\"Number of leaves:\", model.get_n_leaves())\n",
    "\n",
    "display_feature_importances(dt_best, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b3ae3-f262-4874-8404-041bb45bde4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "selectmodel = SelectFromModel(dt_best, prefit=True)\n",
    "X_train_sel_model = selectmodel.transform(X_train)\n",
    "X_test_sel_model = selectmodel.transform(X_test)\n",
    "print(X_train_sel_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30362ea-44e8-47be-831e-bbf1c95db4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "cv_sel_model = GridSearchCV(param_grid=params,\n",
    "                            estimator=LogisticRegression(random_state=random_state, class_weight='balanced'), cv=10)\n",
    "cv_sel_model.fit(X_train_sel_model, y_train)\n",
    "print(\"Train accuracy:\", cv_sel_model.score(X_train_sel_model, y_train))\n",
    "print(\"Test accuracy:\", cv_sel_model.score(X_test_sel_model, y_test))\n",
    "\n",
    "y_pred = cv_sel_model.predict(X_test_sel_model)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(cv_sel_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f4c0a-97a2-42eb-b79a-d26f6fe08957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred_proba_lr = model.predict_proba(X_test)\n",
    "y_pred_proba_lr_cv = cv.predict_proba(X_test)\n",
    "y_pred_proba_rfe_cv = rfe_cv.predict_proba(X_test_sel)\n",
    "y_pred_proba_rfe_log_cv = rfe_log_cv.predict_proba(X_test_sel_log)\n",
    "y_pred_proba_cv_sel_model = cv_sel_model.predict_proba(X_test_sel_model)\n",
    "\n",
    "roc_index_lr = roc_auc_score(y_test, y_pred_proba_lr[:, 1])\n",
    "roc_index_lr_cv = roc_auc_score(y_test, y_pred_proba_lr_cv[:, 1])\n",
    "roc_index_rfe_cv = roc_auc_score(y_test, y_pred_proba_rfe_cv[:, 1])\n",
    "roc_index_rfe_log_cv = roc_auc_score(y_test, y_pred_proba_rfe_log_cv[:, 1])\n",
    "roc_index_cv_sel_model = roc_auc_score(y_test, y_pred_proba_cv_sel_model[:, 1])\n",
    "\n",
    "\n",
    "print(\"ROC index on test for `model`:\", roc_index_lr)\n",
    "print(\"ROC index on test for `cv`:\", roc_index_lr_cv)\n",
    "print(\"ROC index on test for `rfe_cv`:\", roc_index_rfe_cv)\n",
    "print(\"ROC index on test for `rfe_log_cv`:\", roc_index_rfe_cv)\n",
    "print(\"ROC index on test for `cv_sel_model`:\", roc_index_cv_sel_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32411f8c-b717-4929-b89c-b0cae9a2b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_pred_proba_lr[:,1])\n",
    "fpr_lr_cv, tpr_lr_cv, thresholds_lr_cv = roc_curve(y_test, y_pred_proba_lr_cv[:,1])\n",
    "fpr_rfe_cv, tpr_rfe_cv, thresholds_rfe_cv = roc_curve(y_test, y_pred_proba_rfe_cv[:,1])\n",
    "fpr_rfe_log_cv, tpr_rfe_log_cv, thresholds_rfe_log_cv = roc_curve(y_test, y_pred_proba_rfe_log_cv[:,1])\n",
    "fpr_cv_sel_model, tpr_cv_sel_model, thresholds_cv_sel_model = roc_curve(y_test, y_pred_proba_cv_sel_model[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013c8463-89e0-4f72-8bc6-42d22b69e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'ROC Curve for `model` {roc_index_lr:.3f}', color='red',lw=0.5)\n",
    "plt.plot(fpr_lr_cv, tpr_lr_cv, label=f'ROC Curve for `cv` {roc_index_lr_cv:.3f}',color='green', lw=0.5)\n",
    "plt.plot(fpr_rfe_cv, tpr_rfe_cv, label=f'ROC Curve for `rfe_cv` {roc_index_rfe_cv:.3f}',color='blue', lw=0.5)\n",
    "plt.plot(fpr_rfe_log_cv, tpr_rfe_log_cv, label=f'ROC Curve for `rfe_log_cv` {roc_index_rfe_log_cv:.3f}', color='purple', lw=0.5)\n",
    "plt.plot(fpr_cv_sel_model, tpr_cv_sel_model, label=f'ROC Curve for `cv_sel_model`{roc_index_cv_sel_model:.3f}', color='orange', lw=0.5)\n",
    "plt.plot(fpr_dt_cv, tpr_dt_cv, label=f'ROC Curve for `dt_cv` {roc_index_dt_cv:.3f}', color='brown', lw=0.5)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=0.5, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df714fdb-fcad-422c-8d62-8e5bb45c20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr_rfe_cv, tpr_rfe_cv, label=f'ROC Curve for `rfe_cv` {roc_index_rfe_cv:.3f}', color='blue', lw=0.5)\n",
    "plt.plot(fpr_cv_sel_model, tpr_cv_sel_model, label=f'ROC Curve for `cv_sel_model` {roc_index_cv_sel_model:.3f}', color='orange', lw=0.5)\n",
    "plt.plot(fpr_dt_cv, tpr_dt_cv, label=f'ROC Curve for `dt_cv` {roc_index_dt_cv:.3f}', color='brown', lw=0.5)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=0.5, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e43e3b-2066-4d9d-b32b-ca7aa042a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "lr_best = cv_sel_model\n",
    "roc_index_lr_best = roc_index_cv_sel_model\n",
    "tpr_lr_best = tpr_cv_sel_model\n",
    "fpr_lr_best = fpr_cv_sel_model\n",
    "with open('LR.pickle', 'wb') as f:\n",
    "    pickle.dump([lr_best,roc_index_lr_best, fpr_lr_best, tpr_lr_best], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9895a-6d73-4189-a86c-9e4d416d94c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 10\n",
    "test_set_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, stratify=y, random_state=random_state)\n",
    "\n",
    "print(\"Size of training set:\", len(X_train))\n",
    "print(\"Size of testing set:\", len(X_test))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "random_seed = 10\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train, y_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88cee8-15c2-4488-9da9-22b5c5cfe8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = MLPClassifier(random_state=random_state)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6ae4d-dfe1-4b88-b7a6-378438825fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62eb6fd-b393-4918-9493-5aa975b64ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE (random_state = 10)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "# For fixing low precision, recall, f1-score\n",
    "X_train_res = scaler.fit_transform(X_train_res) # scaling X_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc43085-cf88-4206-9b96-c3cb4bcb8a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(random_state=random_state)\n",
    "model.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b03260-f3c1-466d-9b04-6d3292a60585",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(max_iter=500, random_state=random_state)\n",
    "model.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99658572-dfb6-4f4d-831d-79f4dec2c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy:\", model.score(X_train_res, y_train_res))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f97327-0d6a-49e9-8a6a-90e6cbb96fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e913cf-95bf-4a54-9029-950008792839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "params = {'hidden_layer_sizes': [(x,) for x in range(16, 257, 16)]} \n",
    "cv_1 = GridSearchCV(param_grid=params,estimator=MLPClassifier(random_state=random_state), \n",
    "                    return_train_score=True, cv=10, n_jobs=-1)\n",
    "\n",
    "cv_1.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f193a7-1f1a-4117-9b58-2859dc63a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set = cv_1.cv_results_\n",
    "print(result_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb97f105-aa2f-4dad-860d-75b9322656ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_result = result_set['split0_train_score']\n",
    "test_result = result_set['split0_test_score']\n",
    "print(\"Total number of models: \", len(test_result))\n",
    "\n",
    "plt.plot(range(0, len(train_result)), train_result, 'b', range(0,len(test_result)),test_result, 'r')\n",
    "plt.xlabel('Hyperparameter Hidden_layers\\nBlue = training acc. Red = test acc.')\n",
    "plt.xticks(range(0, len(train_result)),range(16, 257, 16))\n",
    "plt.ylabel('score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bcd75f-ef70-43d4-aeea-dae56095c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = result_set['mean_train_score']\n",
    "test_result = result_set['mean_test_score']\n",
    "print(\"Total number of models: \", len(test_result))\n",
    "\n",
    "plt.plot(range(0, len(train_result)), train_result, 'b', range(0,len(test_result)),test_result, 'r')\n",
    "plt.xlabel('Hyperparameter Hidden_layers\\nBlue = training acc. Red = test acc.')\n",
    "plt.xticks(range(0, len(train_result)),range(16, 257, 16))\n",
    "plt.ylabel('score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5d434-0355-482d-8f2b-e44c05336d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy:\", cv_1.score(X_train_res, y_train_res))\n",
    "print(\"Test accuracy:\", cv_1.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv_1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(cv_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505126b-de6e-4609-b606-b125ea521267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new parameters\n",
    "params = {'hidden_layer_sizes': [(12,), (16,), (24,), (32,), (40,), (48,), (56,), (64,)]}\n",
    "cv_2 = GridSearchCV(param_grid=params,\n",
    "                    estimator=MLPClassifier(random_state=random_state), cv=10, n_jobs=-1)\n",
    "cv_2.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(\"Train accuracy:\", cv_2.score(X_train_res, y_train_res))\n",
    "print(\"Test accuracy:\", cv_2.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv_2.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(cv_2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd803e-4015-4a2f-aaaa-8ee0fedf19e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'hidden_layer_sizes': [(12,), (16,), (24,), (32,), (40,), (48,), (56,), (64,)], \n",
    "          'alpha': [0.01, 0.001, 0.0001, 0.00001]}\n",
    "cv_3 = GridSearchCV(param_grid=params,\n",
    "                    estimator=MLPClassifier(random_state=random_state), cv=10, n_jobs=-1)\n",
    "cv_3.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(\"Train accuracy:\", cv_3.score(X_train_res, y_train_res))\n",
    "print(\"Test accuracy:\", cv_3.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv_3.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(cv_3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f7c96-8933-47a6-a87d-d3b535c070db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "rfe = RFECV(estimator = LogisticRegression(random_state=random_state), cv=10)\n",
    "rfe.fit(X_train_res, y_train_res)\n",
    "print(rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b039a-20dd-43dc-be1e-bfbccc51a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe = rfe.transform(X_train_res)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "params = {'hidden_layer_sizes': [(12,), (16,), (24,), (32,), (40,), (48,), (56,), (64,)], \n",
    "          'alpha': [0.01,0.001, 0.0001, 0.00001]}\n",
    "rfe_cv = GridSearchCV(param_grid=params,\n",
    "                      estimator=MLPClassifier(random_state=random_state), cv=10, n_jobs=-1)\n",
    "rfe_cv.fit(X_train_rfe, y_train_res)\n",
    "\n",
    "print(\"Train accuracy:\", rfe_cv.score(X_train_rfe, y_train_res))\n",
    "print(\"Test accuracy:\", rfe_cv.score(X_test_rfe, y_test))\n",
    "\n",
    "y_pred = rfe_cv.predict(X_test_rfe)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(rfe_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4ace2a-f174-4718-af49-8fc0522961b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "with open('decision_tree_model.pickle', 'rb') as f:\n",
    "    dt_best, roc_index_dt_cv, fpr_dt_cv, tpr_dt_cv = pickle.load(f)\n",
    "\n",
    "selectmodel = SelectFromModel(dt_best, prefit=True)\n",
    "X_train_sel_model = selectmodel.transform(X_train_res)\n",
    "X_test_sel_model = selectmodel.transform(X_test)\n",
    "print(X_train_sel_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8acd9b-a4a7-4bdc-bc7b-3b6b4249a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'hidden_layer_sizes': [(12,), (16,), (24,), (32,), (40,), (48,), (56,), (64,)], \n",
    "          'alpha': [0.01,0.001, 0.0001, 0.00001]}\n",
    "cv_sel_model = GridSearchCV(param_grid=params,\n",
    "                            estimator=MLPClassifier(random_state=random_state), cv=10, n_jobs=-1)\n",
    "cv_sel_model.fit(X_train_sel_model, y_train_res)\n",
    "\n",
    "print(\"Train accuracy:\", cv_sel_model.score(X_train_sel_model, y_train_res))\n",
    "print(\"Test accuracy:\", cv_sel_model.score(X_test_sel_model, y_test))\n",
    "\n",
    "y_pred = cv_sel_model.predict(X_test_sel_model)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(cv_sel_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571004a8-57f0-420d-8805-20c1db63e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set = cv_sel_model.cv_results_\n",
    "print(result_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f939d-1954-4669-9ecf-a775add6c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred_proba_nn = model.predict_proba(X_test)\n",
    "y_pred_proba_cv_1 = cv_1.predict_proba(X_test)\n",
    "y_pred_proba_cv_2 = cv_2.predict_proba(X_test)\n",
    "y_pred_proba_cv_3 = cv_3.predict_proba(X_test)\n",
    "y_pred_proba_rfe_cv = rfe_cv.predict_proba(X_test_rfe)\n",
    "y_pred_proba_cv_sel_model = cv_sel_model.predict_proba(X_test_sel_model)\n",
    "\n",
    "roc_index_nn = roc_auc_score(y_test, y_pred_proba_nn[:, 1])\n",
    "roc_index_cv_1 = roc_auc_score(y_test, y_pred_proba_cv_1[:, 1])\n",
    "roc_index_cv_2 = roc_auc_score(y_test, y_pred_proba_cv_2[:, 1])\n",
    "roc_index_cv_3 = roc_auc_score(y_test, y_pred_proba_cv_3[:, 1])\n",
    "roc_index_rfe_cv = roc_auc_score(y_test, y_pred_proba_rfe_cv[:, 1])\n",
    "roc_index_cv_sel_model = roc_auc_score(y_test, y_pred_proba_cv_sel_model[:, 1])\n",
    "\n",
    "print(\"ROC index on test for NN_default:\", roc_index_nn)\n",
    "print(\"ROC index on test for NN with gridsearch 1:\", roc_index_cv_1)\n",
    "print(\"ROC index on test for NN with gridsearch 2:\", roc_index_cv_2)\n",
    "print(\"ROC index on test for NN with gridsearch 3:\", roc_index_cv_3)\n",
    "print(\"ROC index on test for NN with feature selection and gridsearch:\", roc_index_rfe_cv)\n",
    "print(\"ROC index on test for NN with feature selection (model selection) and gridsearch:\", roc_index_cv_sel_model)\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr_nn, tpr_nn, thresholds_nn = roc_curve(y_test, y_pred_proba_nn[:,1])\n",
    "fpr_cv_1, tpr_cv_1, thresholds_cv_1 = roc_curve(y_test, y_pred_proba_cv_1[:,1])\n",
    "fpr_cv_2, tpr_cv_2, thresholds_cv_2 = roc_curve(y_test, y_pred_proba_cv_2[:,1])\n",
    "fpr_cv_3, tpr_cv_3, thresholds_cv_3 = roc_curve(y_test, y_pred_proba_cv_3[:,1])\n",
    "fpr_rfe_cv, tpr_rfe_cv, thresholds_rfe_cv = roc_curve(y_test, y_pred_proba_rfe_cv[:,1])\n",
    "fpr_cv_sel_model, tpr_cv_sel_model, thresholds_cv_sel_model = roc_curve(y_test, y_pred_proba_cv_sel_model[:,1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr_nn, tpr_nn, label='NN_default {:.3f}'.format(roc_index_nn), color='gray', lw=0.5)\n",
    "plt.plot(fpr_cv_1, tpr_cv_1, label='NN cv_1 {:.3f}'.format(roc_index_cv_1), color='cyan', lw=0.5)\n",
    "plt.plot(fpr_cv_2, tpr_cv_2, label='NN cv_2 {:.3f}'.format(roc_index_cv_2), color='yellow', lw=0.5)\n",
    "plt.plot(fpr_cv_3, tpr_cv_3, label='NN cv_3 {:.3f}'.format(roc_index_cv_3), color='blue', lw=0.5)\n",
    "plt.plot(fpr_rfe_cv, tpr_rfe_cv, label='NN rfe_cv {:.3f}'.format(roc_index_rfe_cv), color='black', lw=0.5)\n",
    "plt.plot(fpr_cv_sel_model, tpr_cv_sel_model, label='NN with cv_sel_model {:.3f}'.format(roc_index_cv_sel_model), color='red', lw=0.5)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=0.5, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e357f9-41e8-430c-ac5a-d307a4b66a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('decision_tree_model.pickle', 'rb') as f:\n",
    "    dt_best, roc_index_dt_cv, fpr_dt_cv, tpr_dt_cv = pickle.load(f)  \n",
    "with open('LR.pickle', 'rb') as f:\n",
    "    lr_best, roc_index_lr_cv, fpr_lr_cv, tpr_lr_cv = pickle.load(f)\n",
    "    \n",
    "print(\"ROC index on test for decision tree:\", roc_index_dt_cv)\n",
    "print(\"ROC index on test for linear regression:\", roc_index_lr_cv)\n",
    "print(\"ROC index on test for NN with feature selection (model selection) and gridsearch:\", roc_index_cv_sel_model)\n",
    "\n",
    "plt.plot(fpr_dt_cv, tpr_dt_cv, label='DT {:.3f}'.format(roc_index_dt_cv), color='red', lw=0.5)\n",
    "plt.plot(fpr_lr_cv, tpr_lr_cv, label='LR {:.3f}'.format(roc_index_lr_cv), color='green', lw=0.5)\n",
    "plt.plot(fpr_cv_sel_model, tpr_cv_sel_model, label='NN with cv_sel_model {:.3f}'.format(roc_index_cv_sel_model), color='blue', lw=0.5)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=0.5, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee412f7b-90e7-4228-a12b-b762567c1390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        hidden_layer_size = 100\n",
    "        output_size = 1\n",
    "        self.fc1 = nn.Linear(in_features, hidden_layer_size)\n",
    "        self.fc2 = nn.Linear(hidden_layer_size, output_size)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        data = F.relu(self.fc1(data))\n",
    "        data = self.fc2(data)\n",
    "        data = F.sigmoid(data)\n",
    "        return torch.flatten(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89dccd0-e88f-4609-952a-a8ad933c8874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class that inherits from PyTorch's Dataset class\n",
    "class MyDataset(TorchDataset):\n",
    "    def __init__(self, X, y):\n",
    "        assert (len(X) == len(y))\n",
    "        self.X = X.astype(\"float32\")\n",
    "        self.y = y.astype(\"float32\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx], self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d95b8-1621-491e-acfb-2d24e7949671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-level model class that handles training and prediction\n",
    "class MyModel:\n",
    "    def __init__(self, in_features, batch_size=200):\n",
    "        self.model = MyNet(in_features=in_features)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001)\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.batch_size = batch_size\n",
    "        count = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "        print(f\"The model has {count:,} trainable parameters\")\n",
    "        \n",
    "    def train_one_epoch(self, loader):\n",
    "        for X, y in loader:\n",
    "            out = self.model(X)\n",
    "            loss = self.criterion(out, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "    def train(self, X_train, y_train, X_test, y_test, num_epochs=100):\n",
    "        train_loader = DataLoader(MyDataset(X_train, y_train), batch_size=self.batch_size)\n",
    "        train_acc_history = []\n",
    "        test_acc_history = []\n",
    "        \n",
    "        for i in range(num_epochs):\n",
    "            self.train_one_epoch(train_loader)\n",
    "            train_pred = self.predict(X_train)\n",
    "            train_acc = accuracy_score(y_train, train_pred)\n",
    "            test_pred = self.predict(X_test)\n",
    "            test_acc = accuracy_score(y_test, test_pred)\n",
    "            print(f\"Epoch {i+1}: Train Accuracy: {train_acc} Test Accuracy: {test_acc}\")\n",
    "            train_acc_history.append(train_acc)\n",
    "            test_acc_history.append(test_acc)\n",
    "        return (train_acc_history, test_acc_history)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        loader = DataLoader(MyDataset(X, X), batch_size=self.batch_size, shuffle=False)\n",
    "        results = []\n",
    "        for X_batch, _ in loader:\n",
    "            out = self.model(X_batch)\n",
    "            out = [1 if x >= 0.5 else 0 for x in out.tolist()]\n",
    "            results.extend(out)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713695bd-d3b0-4739-8c93-e56d106f4688",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]\n",
    "model = MyModel(num_features)\n",
    "\n",
    "train_acc_list, test_acc_list = model.train(\n",
    "    X_train_res, y_train_res, \n",
    "    X_test, y_test,\n",
    "    num_epochs=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df279d9c-92b5-4b02-8867-6028afc9c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xlabel(\"Epoch\", size=12)\n",
    "plt.ylabel(\"Accuracy\", size=12)\n",
    "plt.plot(train_acc_list, label=\"Training Accuracy\")\n",
    "plt.plot(test_acc_list, label=\"Testing Accuracy\")\n",
    "plt.grid()\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f4f3af-245f-40d7-a057-a41f45ef01b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_with_highest_accuracy = np.argmax(test_acc_list) + 1\n",
    "print(f\"Epoch with highest accuracy: {epoch_with_highest_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8645d34-d9fb-4e9c-b77d-cb6b6b8e0a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
